---
title: "AI Gateway Overview"
sidebarTitle: "Overview"
description: "Use any LLM provider through a single OpenAI-compatible API with intelligent routing, fallbacks, and unified observability"
---

Helicone AI Gateway provides a unified API for 100+ LLM providers through the OpenAI SDK format. Instead of learning different SDKs and APIs for each provider, use one familiar interface to access any model with intelligent routing, automatic fallbacks, and **complete observability built-in**.

## Why Use AI Gateway?

<CardGroup cols={2}>
<Card title="One SDK for All Models" icon="code">
  Use OpenAI SDK to access GPT, Claude, Gemini, and 100+ other models
</Card>
<Card title="No Rate Limits" icon="gauge">
  Skip provider tier restrictions - use credits with 0% markup
</Card>
<Card title="Always Online" icon="shield-check">
  Automatic failover across providers keeps your app running
</Card>
<Card title="Unified Observability" icon="chart-line">
  Track usage, costs, and performance across all providers in one dashboard
</Card>
</CardGroup>

## How It Works

The AI Gateway sits between your application and LLM providers, acting as a unified translation layer:

1. **You make one request** - Use the OpenAI SDK format, regardless of which provider you want
2. **We translate & route** - Helicone converts your request to the correct provider format (Anthropic, Google, etc.)
3. **Provider responds** - The LLM provider processes your request
4. **We log & return** - You get the response back while we capture metrics, costs, and errors

All through a single endpoint: `https://ai-gateway.helicone.ai`

<Note>
  With credits, we manage provider API keys for you. Your requests automatically work with OpenAI, Anthropic, Google, and 100+ other providers without signing up for each one.
</Note>

## Quick Example

Add two lines to your existing OpenAI code to unlock 100+ models with automatic observability:

```typescript
import { OpenAI } from "openai";

const client = new OpenAI({
  baseURL: "https://ai-gateway.helicone.ai", // [!code ++]
  apiKey: process.env.HELICONE_API_KEY, // [!code ++]
});

const response = await client.chat.completions.create({
  model: "gpt-4o",  // Or: claude-sonnet-4, gemini-2.0-flash, etc.
  messages: [{ role: "user", content: "Hello!" }]
});
```

## Key Features

### Unified API Access

Access 100+ models from different providers using the same OpenAI-compatible format:

```typescript
// All use the exact same API
model: "gpt-4o"              // OpenAI
model: "claude-sonnet-4"     // Anthropic
model: "gemini-2.0-flash"    // Google
model: "llama-3-70b"         // Meta (via multiple providers)
```

### Automatic Provider Routing

The gateway automatically finds the best provider for your model:

- **Multiple providers per model** - Access the same model through OpenAI, Azure, AWS Bedrock, etc.
- **Intelligent selection** - Routes to the cheapest available provider
- **BYOK priority** - Your provider keys are always tried first
- **Load balancing** - Distributes requests across equal-cost providers

[Learn more about provider routing →](/gateway/provider-routing)

### Automatic Fallbacks

Never worry about provider outages again:

```typescript
// Automatically tries Bedrock, then Anthropic, then other providers
model: "claude-sonnet-4/bedrock,claude-sonnet-4/anthropic,claude-sonnet-4"
```

The gateway instantly fails over when it encounters:
- Rate limits (429)
- Authentication errors (401)
- Server errors (500+)
- Timeouts (408)

[Learn more about fallbacks →](/gateway/fallbacks)

### Built-in Observability

Every request through the gateway is automatically logged with:

- **Request/response data** - Full conversation history
- **Cost tracking** - Accurate costs across all providers
- **Performance metrics** - Latency, tokens, and error rates
- **Custom metadata** - User tracking, sessions, properties

View everything in your [Helicone dashboard](https://us.helicone.ai/requests).

### Prompt Management Integration

Deploy and manage prompts without code changes:

```typescript
const response = await client.chat.completions.create({
  model: "gpt-4o-mini",
  prompt_id: "customer_support",
  inputs: {
    customer_name: "Sarah",
    issue_type: "billing"
  }
});
```

[Learn more about prompt integration →](/gateway/prompt-integration)

## Helicone vs OpenRouter

Helicone offers a complete platform for production AI applications, while OpenRouter focuses on simple model access.

| Feature | Helicone | OpenRouter |
|---------|----------|------------|
| **Pricing** | 0% markup | 5.5% markup |
| **Observability** | Full-featured (sessions, users, custom properties, cost tracking) | Basic (requests/costs per model only) |
| **Session Tracking** | ✅ | ❌ |
| **Prompt Management** | ✅ | ❌ |
| **Caching** | ✅ | ❌ |
| **Custom Rate Limits** | ✅ | ❌ |
| **LLM Security** | ✅ | ❌ |
| **Open Source** | ✅ | ❌ |
| **BYOK** | ✅ | ✅ |
| **Automatic Fallbacks** | ✅ | ✅ |

<Accordion title="Migrating from OpenRouter?">
  See our [OpenRouter migration guide](https://www.helicone.ai/blog/migration-openrouter) for step-by-step instructions.
</Accordion>

## Getting Started

<CardGroup cols={2}>
<Card title="Quick Start Guide" icon="rocket" href="/gateway/quickstart">
  Set up the gateway and make your first request in 5 minutes
</Card>
<Card title="Browse Models" icon="list" href="https://helicone.ai/models">
  See all supported models and provider formats
</Card>
<Card title="Provider Routing" icon="route" href="/gateway/provider-routing">
  Configure automatic routing and fallbacks for reliability
</Card>
<Card title="Fallback Strategies" icon="shield-halved" href="/gateway/fallbacks">
  Build resilient apps with automatic provider failover
</Card>
</CardGroup>

## How Credits Work

Instead of managing API keys for each provider, Helicone maintains the keys for you:

- **0% markup** - Pay exactly what providers charge
- **No provider signup** - Access 100+ models immediately
- **Unified billing** - Single invoice across all providers
- **No rate limits** - Skip provider tier restrictions
- **Automatic fallbacks** - Seamless failover between providers

[Add credits to your account →](https://us.helicone.ai/settings/billing)

Want more control? You can [bring your own provider keys](https://us.helicone.ai/providers) instead.

<Note>
Want to integrate a new model provider to the AI Gateway? Contact us on [Discord](https://discord.com/invite/zsSTcH2qhG) or check our GitHub repository for contribution guidelines.
</Note>
